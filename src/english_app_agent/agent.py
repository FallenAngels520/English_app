from langchain.chat_models import init_chat_model
from langgraph.graph import START, END, StateGraph
from langgraph.types import Command, Send
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import (
    HumanMessage,
)

from .state import (
    Decision,
    AgentState,
    WordMemoryResult,
    ImageStyle,
    MnemonicStyle,
    VoiceStyle,
    Phonetic,
    Homophone,
    Meaning,
    WordBlock,
    ImageMedia,
    AudioMedia,
    MediaBlock,
    StylesBlock,
    StatusBlock,
    ImageGenOutput,
    TTSGenOutput,
    FinalReplyOutput,
    AgentInputState
    )
from .utils import (
    get_api_key_for_model,
    generate_image_tool,
    tts_generation_tool,
    to_dict_or_self
)
from .configuration import (
    EnglishAppConfig
    )

from .prompt import(
    main_agent_prompt,
    mnemonic_agent_prompt,
    image_agent_prompt,
    tts_agent_prompt,
    final_result_prompt
    )

from langgraph.checkpoint.memory import InMemorySaver

from typing import Literal, Optional
import json
from datetime import datetime
import asyncio
from dotenv import load_dotenv


# Initialize a configurable model that we will use throughout the agent
configurable_model = init_chat_model(
    configurable_fields=("model", "temperature", "api_key"),
)
# åŠ è½½.envæ–‡ä»¶
load_dotenv()  # ç­‰åŒäº load_dotenv(".env")

async def main_agent_logic(
    state: AgentState,
    config: RunnableConfig
) -> Command[Literal["generate_mnemonic", "generate_image", "generate_tts", "final_result"]]:
    """
    ä¸»æ™ºèƒ½ä½“é€»è¾‘ï¼š
    - æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œå½“å‰çŠ¶æ€ï¼Œç”Ÿæˆå†³ç­– Decision
    - è¿”å›æœ€ç»ˆç»“æœ WordMemoryResult
    """
    # Step 1: Check if clarification is enabled in configuration
    configurable = EnglishAppConfig.from_runnable_config(config)

    # Step 2:Prepare the prompt with current state
    last_msg = state.get("messages", [])
    messages = last_msg[-1].content if last_msg else ""

    model_config = {
        "model": configurable.llm.main_agent_model,
        "temperature": configurable.llm.main_agent_temperature,
        "api_key": get_api_key_for_model(configurable.llm.main_agent_model, config)
    }

    # build json string of current state
    current_style_id = state.get("style_profile_id") or configurable.defaults.default_style_profile_id

    state_context = {
        "word": state.get("word"),
        "mnemonic": state.get("mnemonic"),
        "image_url": state.get("image_url"),
        "audio_url": state.get("audio_url"),
        "style_profile_id": current_style_id,
        "user_mnemonic_pref": to_dict_or_self(state.get("user_mnemonic_pref")) if state.get("user_mnemonic_pref") else None,
        "user_image_pref": to_dict_or_self(state.get("user_image_pref")) if state.get("user_image_pref") else None,
        "user_voice_pref": to_dict_or_self(state.get("user_voice_pref")) if state.get("user_voice_pref") else None,
        # æŠŠä¸Šä¸€è½®çš„å†³ç­–æ”¾å…¥ contextï¼Œå¸®åŠ© LLM ç†è§£è¿ç»­å¯¹è¯
        "last_decision": state.get("last_decision") 
    }

    prompt = main_agent_prompt.replace(
        "{current_state_json}", 
        json.dumps(state_context, ensure_ascii=False)
    ).replace(
        "{user_input}", 
        messages
    )

    # Call the LLM to get the decision
    model = (
        configurable_model
        .with_structured_output(Decision)
        .with_retry(stop_after_attempt=configurable.retry.max_retries)
        .with_config(model_config)
    )

    decision = await model.ainvoke([HumanMessage(content=prompt)])

    # new_word ä¸€å®šè¦æœ‰ mnemonic
    if decision.intent == "new_word":
        decision.need_new_mnemonic = True

    # Route based on the decision
    if decision.need_new_image and not configurable.features.enable_image_generation:
        decision.need_new_image = False
        decision.image_style = None
        decision.reason += " (Configç¦æ­¢ç”Ÿæˆå›¾ç‰‡)"

    if decision.need_new_audio and not configurable.features.enable_tts_generation:
        decision.need_new_audio = False
        decision.voice_style = None
        decision.reason += " (Configç¦æ­¢ç”Ÿæˆè¯­éŸ³)"

    # å®‰å…¨ç­–ç•¥ï¼šå¦‚æœ Config ä¸å…è®¸ strong_aggressiveï¼Œä½† style é€‰äº† aggressive
    if (decision.style_profile_id == "aggressive" and not configurable.safety.allow_strong_aggressive):
        # é™çº§å¤„ç†ï¼Œæˆ–è€…åœ¨ mnemonic_style é‡Œé™åˆ¶
        if decision.mnemonic_style and decision.mnemonic_style.humor == "aggressive":
             decision.mnemonic_style.humor = "dark" # é™çº§ä¸º dark
             decision.reason += " (å®‰å…¨ç­–ç•¥é™åˆ¶ï¼Œé™çº§ä¸ºdark)"

    # ä»…é’ˆå¯¹â€œæ–°å­¦å•è¯â€æ„å›¾æ‰§è¡Œæ­¤ç­–ç•¥
    if decision.intent == "new_word":
        # ğŸš¨ ç­–ç•¥ A: Unknown -> ç†”æ–­ (è®¤å®šä¸æ˜¯æœ‰æ•ˆå•è¯)
        if decision.difficulty == "unknown":
            # å¼ºåˆ¶ä¿®æ”¹æ„å›¾ä¸ºâ€œæ— å…³/æ— æ³•å¤„ç†â€ï¼Œé˜²æ­¢ä¸‹æ¸¸ Agent æµªè´¹ Token
            decision.intent = "out_of_scope"
            
            # å…³é—­æ‰€æœ‰ç”Ÿæˆå¼€å…³
            decision.need_new_mnemonic = False
            decision.need_new_image = False
            decision.need_new_audio = False
            
            # è®°å½•åŸå› ï¼ŒFinal Result èŠ‚ç‚¹å¯ä»¥æ®æ­¤ç”Ÿæˆæç¤ºæ–‡æ¡ˆ
            decision.reason = "ç³»ç»Ÿæ— æ³•è¯†åˆ«è¯¥è¾“å…¥ä¸ºæœ‰æ•ˆå•è¯ï¼Œæˆ–éš¾åº¦åˆ¤å®šå¤±è´¥ï¼Œåœæ­¢ç”Ÿæˆã€‚"

        # âœ… ç­–ç•¥ B: Medium / Hard -> å¼ºåˆ¶é…å›¾ (è¾…åŠ©è®°å¿†)
        elif decision.difficulty in ["medium", "hard"]:
            # æ£€æŸ¥ï¼šå¦‚æœåŠŸèƒ½å¼€å¯ï¼Œä¸”å½“å‰æœªå¼€å¯é…å›¾
            if configurable.features.enable_image_generation and not decision.need_new_image:
                decision.need_new_image = True
                decision.reason += f" [Strategy:ç›‘æµ‹åˆ°{decision.difficulty}éš¾è¯ï¼Œè‡ªåŠ¨è¡¥å……é…å›¾]"
                
                # è‡ªåŠ¨è¡¥å…¨ Style (é˜²æ­¢ LLM ç»™ç©ºå€¼)
                if not decision.image_style:
                    # ä¼˜å…ˆå–ç”¨æˆ·åå¥½ï¼Œæ²¡æœ‰åˆ™å– Config é»˜è®¤
                    default_style = state.get("user_image_pref")
                    if not default_style:
                        # æ„é€ é»˜è®¤ ImageStyle (éœ€å¯¼å…¥ ImageStyle ç±»)
                        decision.image_style = ImageStyle(
                            need_image=True,
                            style=configurable.defaults.default_image_style,
                            mood=configurable.defaults.default_image_mood,
                            extra_tags=[]
                        )
                    else:
                        decision.image_style = default_style

        # ğŸ›‘ ç­–ç•¥ C: Easy -> å¼ºåˆ¶ä¸é…å›¾ (èŠ‚çœæˆæœ¬/ä¿æŒæ¸…çˆ½)
        elif decision.difficulty == "easy":
            # å³ä½¿ LLM æƒ³è¦ç”»ï¼Œæˆ‘ä»¬ä¹Ÿå¼ºåˆ¶å…³é—­
            if decision.need_new_image:
                decision.need_new_image = False
                decision.image_style = None # æ¸…ç©ºé£æ ¼
                decision.reason += " [Strategy:ç®€å•è¯æ±‡å¼ºåˆ¶è·³è¿‡é…å›¾]"

    # 5. å‡†å¤‡çŠ¶æ€æ›´æ–° (State Update)
    # è¿™äº›å†…å®¹ä¼šç«‹å³å†™å…¥ StateGraph çš„ checkpoint
    had_existing_image = bool(state.get("image_url"))

    if decision.need_new_mnemonic:
        # Mnemonic/story æ›´æ–°åï¼Œç¡®ä¿å¤šåª’ä½“åŒæ­¥åˆ·æ–°
        if configurable.features.enable_tts_generation:
            decision.need_new_audio = True

        if configurable.features.enable_image_generation and (had_existing_image or decision.need_new_image):
            decision.need_new_image = True
            if not decision.image_style:
                decision.image_style = state.get("user_image_pref") or ImageStyle(
                    need_image=True,
                    style=configurable.defaults.default_image_style,
                    mood=configurable.defaults.default_image_mood,
                    extra_tags=[]
                )

    previous_word = state.get("word")
    resolved_word = decision.word or previous_word

    update_dict = {
        "decision": decision,
        "last_decision": decision.model_dump(), # å­˜ä¸€ä¸‹ç»™ä¸‹ä¸€è½®å‚è€ƒ
        # å¦‚æœæ˜¯æ–°è¯ï¼Œæ›´æ–° wordï¼›å¦åˆ™ä¿æŒåŸæ ·
        "word": resolved_word,
        # æ€»æ˜¯æ›´æ–°å½“å‰é£æ ¼ ID
        "style_profile_id": decision.style_profile_id or current_style_id
    }

    # å¦‚æœ scope æ˜¯ session_defaultï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ›´æ–°ç”¨æˆ·é•¿æœŸåå¥½
    # æ³¨æ„ï¼šAgentState å®šä¹‰é‡Œæœ‰ user_*_prefï¼Œè¿™é‡Œè¿›è¡Œå†™å…¥
    if decision.scope == "session_default" and configurable.preferences.allow_update_preferences:
        if decision.mnemonic_style:
            update_dict["user_mnemonic_pref"] = decision.mnemonic_style
        if decision.image_style:
            update_dict["user_image_pref"] = decision.image_style
        if decision.voice_style:
            update_dict["user_voice_pref"] = decision.voice_style
    
    # 6. æ ¸å¿ƒè·¯ç”±é€»è¾‘ (Routing Logic)
    # æ ¹æ®ä½ çš„è¦æ±‚ï¼šä¼˜å…ˆç”Ÿæˆè°éŸ³(Mnemonic)ï¼Œç„¶åæ‰æ˜¯ å›¾ç‰‡/è¯­éŸ³
    
    # åœºæ™¯ A: éœ€è¦ç”Ÿæˆæ–°è°éŸ³ (new_word æˆ– refine_mnemonic)
    # å¿…é¡»å…ˆå» mnemonic_agentï¼Œå› ä¸ºå®ƒäº§ç”Ÿçš„ story æ˜¯ä¸‹æ¸¸ image/tts çš„è¾“å…¥
    if decision.need_new_mnemonic:
        return Command(
            update=update_dict,
            goto="generate_mnemonic"
        )

    # åœºæ™¯ B: ä¸éœ€è¦æ”¹æ–‡å­—ï¼Œåªæ”¹å¤šåª’ä½“
    need_img = decision.need_new_image
    need_audio = decision.need_new_audio
    audio_flow = decision.audio_flow  # "parallel" | "after_image" | "audio_only"

    # 1) æ—¢è¦å›¾åˆè¦éŸ³
    if need_img and need_audio:
        if audio_flow == "parallel":
            # å¹¶è¡Œï¼šä¸» agent ç›´æ¥å¹¶è¡Œè°ƒå›¾ + éŸ³
            return Command(
                update=update_dict,
                goto=["generate_image", "generate_tts"]
            )
        elif audio_flow == "after_image":
            # ä¸²è¡Œï¼šå…ˆå›¾ï¼Œgenerate_image ç»“æŸåå†è·³è½¬åˆ° TTS
            return Command(
                update=update_dict,
                goto="generate_image"
            )
        elif audio_flow == "audio_only":
            # ç†è®ºä¸Šä¸ä¼šå‡ºç°â€œæ—¢è¦å›¾åˆ audio_onlyâ€ï¼Œè¿™é‡Œå…œåº•ï¼šåªèµ°è¯­éŸ³
            return Command(
                update=update_dict,
                goto="generate_tts"
            )

    # 2) åªè¦å›¾ç‰‡
    if need_img and not need_audio:
        return Command(
            update=update_dict,
            goto="generate_image"
        )

    # 3) åªè¦è¯­éŸ³
    if need_audio and not need_img:
        return Command(
            update=update_dict,
            goto="generate_tts"
        )

    # 4) éƒ½ä¸è¦ï¼šç›´æ¥ç»ˆç‚¹
    return Command(
        update=update_dict,
        goto="final_result"
    )
    
    # åœºæ™¯ C: ä¸éœ€è¦ç”Ÿæˆä»»ä½•å†…å®¹
    # ä¾‹å¦‚ï¼šintent="explain", "small_talk", "out_of_scope", "update_preferences"
    # ç›´æ¥å»ç»ˆç‚¹ï¼ˆæˆ–è€…å»ä¸€ä¸ªå›å¤ç”Ÿæˆçš„èŠ‚ç‚¹ï¼Œè¿™é‡Œç®€åŒ–ä¸º final_resultï¼‰
    return Command(
        update=update_dict,
        goto="final_result"
    )


async def generate_mnemonic(state: AgentState,
                            config: RunnableConfig) -> Command[Literal["generate_image", "generate_tts", "final_result"]]:
    """
    è°éŸ³æ¢—æ™ºèƒ½ä½“é€»è¾‘ï¼š
    - æ ¹æ®ä¸»æ™ºèƒ½ä½“çš„å†³ç­–ï¼Œç”Ÿæˆæ–°çš„è°éŸ³æ¢—å’Œåœºæ™¯æ•…äº‹
    - è¿”å›æ›´æ–°åçš„çŠ¶æ€ï¼Œç»§ç»­åç»­ç”Ÿæˆï¼ˆå›¾ç‰‡/è¯­éŸ³ï¼‰æˆ–ç»ˆç‚¹
    """
    # Step 1: Load configuration
    configurable = EnglishAppConfig.from_runnable_config(config)
    model_config = {
        "model": configurable.llm.mnemonic_agent_model,
        "temperature": configurable.llm.mnemonic_agent_temperature,
        "api_key": get_api_key_for_model(configurable.llm.mnemonic_agent_model, config)
    }

    decision = state.get("decision")

    # ========== 2. ç¡®å®šç›®æ ‡å•è¯ ==========
    # ä¼˜å…ˆä½¿ç”¨ Decision æŒ‡æ´¾çš„æ–°è¯ï¼›å¦‚æœæ˜¯ refine_mnemonicï¼Œåˆ™ä½¿ç”¨ state ä¸­çš„æ—§è¯(stateæ˜¯è®°å½•å½“å‰å•è¯çš„)
    target_word = decision.word if decision and decision.word else state.get("word")

    if not target_word:
        # æ— æ³•ç»§ç»­ï¼Œç›´æ¥è·³åˆ°ç»ˆç‚¹
        return Command(
            update={"reply_text": "ç³»ç»Ÿé”™è¯¯ï¼šæœªæ‰¾åˆ°ç›®æ ‡å•è¯ã€‚"},
            goto="final_result"
        )
    
    # ========== 3. ç¡®å®šé£æ ¼ (Style Resolution) ==========
    # ä¼˜å…ˆçº§ï¼šæœ¬è½®å†³ç­– > ç”¨æˆ·é•¿æœŸåå¥½ > ç³»ç»Ÿé»˜è®¤
    final_style = None

    # A. æ£€æŸ¥æœ¬è½®å†³ç­–
    if decision and decision.mnemonic_style:
        final_style = decision.mnemonic_style
    
    # B. æ£€æŸ¥ç”¨æˆ·åå¥½ (State)
    if not final_style and state.get("user_mnemonic_pref"):
        final_style = state.get("user_mnemonic_pref")
        
    # C. ä½¿ç”¨ Config é»˜è®¤å…œåº•
    if not final_style:
        # éœ€å¯¼å…¥ MnemonicStyle æ¨¡å‹
        final_style = MnemonicStyle(
            humor=configurable.defaults.default_mnemonic_humor,
            dialect=configurable.defaults.default_mnemonic_dialect,
            complexity="normal",
            extra_tags=[]
        )
    
    # ========== 4. è°ƒç”¨ LLM ç”Ÿæˆ ==========
    model = (
        configurable_model
        .with_structured_output(WordBlock)
        .with_retry(stop_after_attempt=configurable.retry.max_retries)
        .with_config(model_config)
    )
    # åºåˆ—åŒ–é£æ ¼å‚æ•°
    style_json = json.dumps(final_style.model_dump(), ensure_ascii=False)
    formatted_prompt = mnemonic_agent_prompt.replace("{word}", target_word).replace("{mnemonic_style_json}", style_json)

    response = await model.ainvoke([HumanMessage(content=formatted_prompt)])

    # ========== 5. å‡†å¤‡çŠ¶æ€æ›´æ–° (State Update) ==========
    # å°†å®Œæ•´ç»“æ„å­˜å…¥ word_block_partialï¼Œæ–¹ä¾¿ final_result ç»„è£…æœ€ç»ˆç»“æœ
    update_dict = {
        "word": target_word,
        "mnemonic": response.homophone.text,
        "scene_text": response.story,
        "meaning": response.meaning.cn,
        "word_block_partial": response
    }

    # ========== 6. å…³é”®è·¯ç”±é€»è¾‘ (Routing) ==========
    # ä»»åŠ¡å·²å®Œæˆï¼Œç°åœ¨æŸ¥çœ‹ Main Agent çš„åŸå§‹å†³ç­–ï¼Œå†³å®šä¸‹ä¸€æ­¥å»å“ªé‡Œ
    if not decision:
        return Command(update=update_dict, goto="final_result")

    need_img = decision.need_new_image
    need_audio = decision.need_new_audio
    audio_flow = decision.audio_flow  # "parallel" | "after_image" | "audio_only"

    # 1) å›¾ + å£°
    if need_img and need_audio:
        if audio_flow == "parallel":
            return Command(
                update=update_dict,
                goto=["generate_image", "generate_tts"]
            )
        elif audio_flow == "after_image":
            return Command(
                update=update_dict,
                goto="generate_image"
            )
        elif audio_flow == "audio_only":
            # å†²çªå…œåº•ï¼šåªåšè¯­éŸ³
            return Command(
                update=update_dict,
                goto="generate_tts"
            )

    # 2) åªè¦å›¾
    if need_img and not need_audio:
        return Command(
            update=update_dict,
            goto="generate_image"
        )

    # 3) åªè¦éŸ³é¢‘
    if need_audio and not need_img:
        return Command(
            update=update_dict,
            goto="generate_tts"
        )

    # 4) éƒ½ä¸è¦
    return Command(
        update=update_dict,
        goto="final_result"
    )

async def generate_image(state: AgentState,
                         config: RunnableConfig) -> Command[Literal["generate_tts", "final_result"]]:
    """å›¾ç‰‡ç”Ÿæˆæ™ºèƒ½ä½“é€»è¾‘ï¼š
    - æ ¹æ®ä¸»æ™ºèƒ½ä½“çš„å†³ç­–ï¼Œç”Ÿæˆæ–°çš„å›¾ç‰‡
    - è¿”å›æ›´æ–°åçš„çŠ¶æ€ï¼Œç»§ç»­åç»­ç”Ÿæˆï¼ˆè¯­éŸ³ï¼‰æˆ–ç»ˆç‚¹
    """
    # Load configuration
    configurable = EnglishAppConfig.from_runnable_config(config)
    model_config = {
        "model": configurable.llm.main_agent_model,
        "temperature": configurable.llm.main_agent_temperature,
        "api_key": get_api_key_for_model(configurable.llm.main_agent_model, config)
    }

    decision = state.get("decision")
    
    # 1. ä¸šåŠ¡æ‰§è¡Œé€»è¾‘ (ä¿æŒä¸å˜ï¼Œç”Ÿæˆå›¾ç‰‡)
    # 1.1 å¼€å…³ä¸æ•°æ®æ ¡éªŒ
    should_skip = False
    if not configurable.features.enable_image_generation:
        print("ğŸš« [Image Agent] Disabled by config.")
        should_skip = True
    
    target_word = decision.word if decision and decision.word else state.get("word")
    scene_text = state.get("scene_text")
    if not scene_text:
        print("âš ï¸ [Image Agent] Missing scene_text. Skipping.")
        should_skip = True
    
    image_url = None

    # 1.2 å¦‚æœä¸è·³è¿‡ï¼Œæ‰§è¡Œç”Ÿæˆ
    if not should_skip:
        # Style Resolution (æœ¬è½® > ç”¨æˆ·åå¥½ > é»˜è®¤)
        final_image_style = None
        if decision and decision.image_style:
            final_image_style = decision.image_style
        elif state.get("user_image_pref"):
            final_image_style = state.get("user_image_pref")
        else:
            final_image_style = ImageStyle(
                need_image=True,
                style=configurable.defaults.default_image_style,
                mood=configurable.defaults.default_image_mood,
                extra_tags=[]
            )
        
        # è°ƒç”¨ LLM ç”Ÿæˆå›¾ç‰‡ Prompt
        model = (
            configurable_model
            .with_structured_output(ImageGenOutput)
            .with_retry(stop_after_attempt=configurable.retry.max_retries)
            .with_config(model_config)
        )
        style_json = json.dumps(final_image_style.model_dump(), ensure_ascii=False)
        formatted_prompt = image_agent_prompt.replace("{word}", target_word).replace("{scene_text}", scene_text).replace("{image_style_json}", style_json)

        response = await model.ainvoke([HumanMessage(content=formatted_prompt)])

        try:
            # è°ƒç”¨å›¾ç‰‡ç”Ÿæˆå·¥å…· (å‡è®¾æœ‰ä¸€ä¸ª image_generation_tool å‡½æ•°)
            image_url = await generate_image_tool(response.image_prompt, response.negative_prompt, json.loads(style_json), api_key=get_api_key_for_model("qwen", config))
        except Exception as e:
            print(f"âŒ [Image Agent] Failed: {e}")
            # å›¾ç‰‡å¤±è´¥ä¸é˜»æ–­æµç¨‹ï¼Œç»§ç»­å¾€ä¸‹èµ°
        
    # 2. è·¯ç”±é€»è¾‘ (Routing Logic) - æ ¸å¿ƒä¿®æ”¹
    update_dict = {}
    if image_url:
        update_dict["image_url"] = image_url
    
    # 4. è·¯ç”±é€»è¾‘ï¼š
    #    åªæœ‰åœ¨ audio_flow == "after_image" çš„åœºæ™¯ï¼Œæ‰ç”±å›¾ç‰‡èŠ‚ç‚¹ä¸²åˆ° TTS
    need_audio = decision and decision.need_new_audio
    audio_enabled = configurable.features.enable_tts_generation
    audio_flow = decision.audio_flow if decision else "parallel"

    if need_audio and audio_enabled and audio_flow == "after_image":
        # ä¸²è¡Œæ¨¡å¼ï¼šå›¾ç‰‡å®Œæˆåè¿›å…¥è¯­éŸ³ç”Ÿæˆ
        return Command(
            update=update_dict,
            goto="generate_tts"
        )
    else:
        # å¹¶è¡Œæ¨¡å¼ï¼ˆparallelï¼‰ä¸‹ï¼ŒTTS å·²ç”± main_agent æˆ– generate_mnemonic å¹¶è¡Œè§¦å‘ï¼›
        # æˆ–è€…æœ¬è½®æ ¹æœ¬ä¸éœ€è¦è¯­éŸ³ â†’ ç›´æ¥æ±‡æ€»
        return Command(
            update=update_dict,
            goto="final_result"
        )


async def generate_tts(state: AgentState,
                       config: RunnableConfig) -> Command[Literal["final_result"]]:
    """è¯­éŸ³ç”Ÿæˆæ™ºèƒ½ä½“é€»è¾‘ï¼š
    - æ ¹æ®ä¸»æ™ºèƒ½ä½“çš„å†³ç­–ï¼Œç”Ÿæˆæ–°çš„è¯­éŸ³
    - è¿”å›æ›´æ–°åçš„çŠ¶æ€ï¼Œç»§ç»­åç»­ç”Ÿæˆï¼ˆæœ€ç»ˆç»“æœï¼‰
    """
    # Load configuration
    configurable = EnglishAppConfig.from_runnable_config(config)
    model_config = {
        "model": configurable.llm.main_agent_model,
        "temperature": configurable.llm.main_agent_temperature,
        "api_key": get_api_key_for_model(configurable.llm.main_agent_model, config)
    }

    decision = state.get("decision")

    # 2. å¼€å…³æ ¡éªŒ (Feature Flag)
    if not configurable.features.enable_tts_generation:
        print("ğŸš« [TTS Agent] Feature disabled by config.")
        return Command(goto="final_result")
    
    # 3. æ•°æ®å‡†å¤‡ (Data Prep)
    target_word = decision.word if decision and decision.word else state.get("word")
    mnemonic_text = state.get("mnemonic")
    story_text = state.get("scene_text")

    if not (target_word and mnemonic_text and story_text):
        print(f"âš ï¸ [TTS Agent] Missing text components for '{target_word}'. Skipping.")
        return Command(
            update={"reply_text": "è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼šç¼ºå°‘å¿…è¦çš„æ–‡æœ¬å†…å®¹ã€‚"},
            goto="final_result"
        )
    
    # ç»„åˆåŸå§‹æ–‡æœ¬ï¼š å•è¯ + è°éŸ³ + æ•…äº‹
    full_raw_text = f"{target_word}ã€‚{mnemonic_text}ã€‚{story_text}"

    # 4. ç¡®å®šè¯­éŸ³é£æ ¼ (Style Resolution)
    # ä¼˜å…ˆçº§ï¼šæœ¬è½®å†³ç­– > ç”¨æˆ·é•¿æœŸåå¥½ > ç³»ç»Ÿé»˜è®¤
    final_voice_style = None

    # A. æœ¬è½®å†³ç­–
    if decision and decision.voice_style:
        final_voice_style = decision.voice_style
    
    # B. ç”¨æˆ·åå¥½
    if not final_voice_style and state.get("user_voice_pref"):
        final_voice_style = state.get("user_voice_pref")
    
    # C. ç³»ç»Ÿé»˜è®¤
    if not final_voice_style:
        final_voice_style = VoiceStyle(
            gender=configurable.defaults.default_voice_gender,
            energy=configurable.defaults.default_voice_energy,
            pitch="medium",
            speed=configurable.defaults.default_voice_speed,
            tone="normal"
        )

    # 5. è°ƒç”¨ LLM è¿›è¡Œè¯­éŸ³å‚æ•°ç¼–æ’ (Director Logic)
    model = (
        configurable_model
        .with_structured_output(TTSGenOutput)
        .with_retry(stop_after_attempt=configurable.retry.max_retries)
        .with_config(model_config)
    )
    style_json = json.dumps(final_voice_style.model_dump(), ensure_ascii=False)
    formatted_prompt = tts_agent_prompt.replace("{word}", target_word)\
                                       .replace("{text}", full_raw_text)\
                                       .replace("{voice_style_json}", style_json)
    
    response = await model.ainvoke([HumanMessage(content=formatted_prompt)])

    # 6. ä¼šå‘˜æƒç›Š/æƒé™é™çº§ (Optional Business Logic)
    # å¦‚æœ Config ä¸å…è®¸é«˜çº§è¯­éŸ³ï¼Œä½† LLM é€‰äº† dynamic ç­‰é«˜çº§éŸ³è‰²ï¼Œå¼ºåˆ¶å›é€€
    final_voice_id = response.voice_preset_id
    if not configurable.features.enable_premium_voices:
        # todo: è¿™é‡Œç®€å•ç¤ºä¾‹ï¼Œå®é™…å¯æŸ¥è¡¨
        if "dynamic" in final_voice_id or "expressive" in final_voice_id:
             final_voice_id = "standard_neutral"
             print("â„¹ï¸ [TTS Agent] Downgraded to standard voice due to config.")

    # 7. è°ƒç”¨ TTS å·¥å…· (Tool Execution)
    audio_url = None

    try:
        # è°ƒç”¨è¯­éŸ³ç”Ÿæˆå·¥å…· (å‡è®¾æœ‰ä¸€ä¸ª generate_audio_tool å‡½æ•°)
        audio_url = await tts_generation_tool(
            text=response.text_to_speak,
            api_key=get_api_key_for_model("qwen-tts", config)
            )
    except Exception as e:
        print(f"âŒ [TTS Agent] Failed: {e}")
        # è¯­éŸ³å¤±è´¥ä¸é˜»æ–­æµç¨‹ï¼Œç»§ç»­å¾€ä¸‹èµ°

    # 8. æ›´æ–°çŠ¶æ€å¹¶æ±‡èš
    # æŒ‡å‘ final_resultï¼Œé…åˆ LangGraph å¹¶è¡Œæœºåˆ¶
    return Command(
        update={
            "audio_url": audio_url,
            "audio_voice_profile_id": final_voice_id,  # æ–°å­—æ®µ
        },
        goto="final_result"
    )


async def final_result(state: AgentState,
                       config: RunnableConfig):
    """æœ€ç»ˆç»“æœæ™ºèƒ½ä½“é€»è¾‘ï¼š
    """
    # Load configuration
    configurable = EnglishAppConfig.from_runnable_config(config)
    model_config = {
        "model": configurable.llm.main_agent_model,
        "temperature": configurable.llm.main_agent_temperature,
        "api_key": get_api_key_for_model(configurable.llm.main_agent_model, config)
    }

    decision = state.get("decision")

    # è·å–åŸºç¡€å…ƒæ•°æ®
    intent = decision.intent if decision else "unknown"
    target_word = decision.word if decision and decision.word else state.get("word") or "unknown"
    current_style_id = state.get("style_profile_id") or configurable.defaults.default_style_profile_id

    # å‡†å¤‡æœ€ç»ˆè¾“å‡ºçš„ Prompt
    """
    formatted_prompt = final_result_prompt\
    .replace("{intent}", intent)\
    .replace("{word}", target_word)\
    .replace("{style_profile_id}", current_style_id)\
    .replace("{mnemonic}", state.get("mnemonic") or "")\
    .replace("{scene_text}", state.get("scene_text") or "")\
    .replace("{meaning}", state.get("meaning") or "")

    """
    formatted_prompt = final_result_prompt.replace("{intent}", intent)\
                                          .replace("{word}", target_word)\
                                          .replace("{style_profile_id}", current_style_id)
    model = (
        configurable_model
        .with_structured_output(FinalReplyOutput)
        .with_retry(stop_after_attempt=configurable.retry.max_retries)
        .with_config(model_config)
    )

    response = await model.ainvoke([HumanMessage(content=formatted_prompt)])
    final_reply_text = response.reply_text

    # Small talk / Out of Scope: ä¸ç”Ÿæˆå•è¯å¡ç‰‡
    if intent in ["out_of_scope", "small_talk"]:
        return Command(
            update={
                "reply_text": final_reply_text,
                "final_output": None
            },
            goto=END
        )
    
    # æ„é€ æœ€ç»ˆçš„ WordMemoryResult
    # --- A. ç»„è£… WordBlock ---
    partial = state.get("word_block_partial")

    if partial and isinstance(partial, WordBlock):
        word_block_obj = partial
    else:
        # é™çº§ç­–ç•¥ï¼šå¦‚æœ mnemonic æ²¡è¿è¡Œ(å¦‚åªæ”¹å›¾)ï¼Œä» state æ‰å¹³å­—æ®µæ‹¼å‡‘
        # è¿™ç§æƒ…å†µä¸‹éŸ³æ ‡(ipa)å¯èƒ½ä¼šç¼ºå¤±ï¼Œéœ€ç»™é»˜è®¤å€¼
        word_block_obj = WordBlock(
            word=target_word,
            phonetic=Phonetic(ipa="", pronunciation_note=""),
            homophone=Homophone(
                text=state.get("mnemonic") or "ç”Ÿæˆä¸­...",
                raw="",
                explanation=""
            ),
            story=state.get("scene_text") or "æš‚æ— æ•…äº‹",
            meaning=Meaning(
                pos="unknown",
                cn=state.get("meaning") or "æš‚æ— é‡Šä¹‰"
            )
        )
    
    # --- B. ç»„è£… MediaBlock ---
    # æ£€æŸ¥ Image
    img_obj = None
    if state.get("image_url"):
        # å°è¯•è·å–é£æ ¼
        s_style = "comic" # é»˜è®¤
        s_mood = "funny"
        if decision and decision.image_style:
            s_style = decision.image_style.style
            s_mood = decision.image_style.mood

        img_obj = ImageMedia(
            url=state.get("image_url"),
            style=s_style if s_style != "none" else "comic",
            mood=s_mood,
            updated_at=datetime.now().isoformat()
        )
    
    # æ£€æŸ¥ Audio
    audio_obj = None
    if state.get("audio_url"):
        audio_obj = AudioMedia(
            url=state.get("audio_url"),
            voice_profile_id=state.get("audio_voice_profile_id"),
            duration_sec=0.0, # éœ€åç«¯è®¡ç®—ï¼Œæ­¤å¤„å ä½
            updated_at=datetime.now().isoformat()
        )
    
    media_block_obj = MediaBlock(image=img_obj, audio=audio_obj)

    # --- C. ç»„è£… StylesBlock ---
    styles_block_obj = StylesBlock(
        style_profile_id=current_style_id,
        mnemonic_style=decision.mnemonic_style if decision else None,
        image_style=decision.image_style if decision else None,
        voice_style=decision.voice_style if decision else None
    )

    # --- D. ç»„è£… StatusBlock ---
    updated_parts_list = []
    reason_str = "Generated."
    scope_str = "this_turn"

    if decision:
        if decision.need_new_mnemonic: updated_parts_list.append("mnemonic")
        if decision.need_new_image: updated_parts_list.append("image")
        if decision.need_new_audio: updated_parts_list.append("audio")
        reason_str = decision.reason
        scope_str = decision.scope

    status_block_obj = StatusBlock(
        is_first_time=False, # è¿™é‡Œæš‚å®šFalseï¼Œå®é™…ä¸šåŠ¡éœ€åˆ¤æ–­DB
        intent=intent,
        updated_parts=updated_parts_list,
        scope=scope_str,
        reason=reason_str
    )

    # æœ€ç»ˆæ„å»º WordMemoryResult
    final_result_obj = WordMemoryResult(
        type="word_memory",
        intent=intent,
        word_block=word_block_obj,
        media=media_block_obj,
        styles=styles_block_obj,
        status=status_block_obj
    )

    # å°† Pydantic å¯¹è±¡è½¬ä¸º Dict å­˜å…¥ State (æ–¹ä¾¿ JSON åºåˆ—åŒ–ä¼ ç»™å‰ç«¯)
    return Command(
        update={
            "reply_text": final_reply_text,
            "final_output": final_result_obj
        },
        goto=END
    )


english_app_agent_graph = StateGraph(AgentState)
english_app_agent_graph.add_node("main_agent_logic", main_agent_logic)
english_app_agent_graph.add_node("generate_mnemonic", generate_mnemonic)
english_app_agent_graph.add_node("generate_image", generate_image)
english_app_agent_graph.add_node("generate_tts", generate_tts)
english_app_agent_graph.add_node("final_result", final_result)

english_app_agent_graph.add_edge(START, "main_agent_logic")
english_app_agent_graph.add_edge("final_result", END)

config = {"configurable": {"thread_id": "english_app_agent_thread"}}
checkpointer = InMemorySaver()

app_agent = english_app_agent_graph.compile(checkpointer=checkpointer)

async def run_agent():
    input_data = {
        "messages": [HumanMessage(content="å¸®æˆ‘è§£é‡Šè¿™ä¸ªå•è¯ 'dependency' å¹¶ç”Ÿæˆä¸€ä¸ªæœ‰è¶£çš„è®°å¿†æ–¹æ³•ã€‚")],
    }
    result = await app_agent.ainvoke(input_data, config=config)
    print(result)

asyncio.run(run_agent())